% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/relhold.R
\name{rel_after_cap_actions}
\alias{rel_after_cap_actions}
\title{Fix action profiles for the equilibrium path (ae) and during punishment (a1.hat and a2.hat) that are assumed to be played after the cap in period T onwards. The punishment profile a1.hat is the profile in which player 1 already plays a best-reply (in a1 he might play a non-best reply). From the specified action profiles in all states, we can compute the relevant after-cap payoffs U(x), v1(x) and v2(x) assuming that state transitions would continue.}
\usage{
rel_after_cap_actions(g, x = NA, ae, a1.hat, a2.hat, x.T = NA)
}
\arguments{
\item{g}{a relational contracting game created with rel_game}

\item{x}{The state(s) for which this after-cap payoff set is applied. If NA (default) and also x.T is NA, it applies to all states.}

\item{ae}{A named list that specifies the equilibrum action profiles.}

\item{a1.hat}{A named list that specifies the action profile when player 1 is punished.}

\item{a2.hat}{A named list that specifies the action profile when player 2 is punished.}

\item{x.T}{Instead of specifiying the argument x, we can specify as x.T a name of the after-cap state. This can be  refereed to as the argument x.T in rel_state and rel_states}
}
\value{
Returns the updated game
}
\description{
Fix action profiles for the equilibrium path (ae) and during punishment (a1.hat and a2.hat) that are assumed to be played after the cap in period T onwards. The punishment profile a1.hat is the profile in which player 1 already plays a best-reply (in a1 he might play a non-best reply). From the specified action profiles in all states, we can compute the relevant after-cap payoffs U(x), v1(x) and v2(x) assuming that state transitions would continue.
}
